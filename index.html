<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Speech-to-Text - Phase 2: WASM</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 20px;
        }

        .container {
            background: white;
            border-radius: 20px;
            padding: 40px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
            max-width: 700px;
            width: 100%;
        }

        h1 {
            color: #333;
            margin-bottom: 10px;
            font-size: 28px;
        }

        .subtitle {
            color: #666;
            margin-bottom: 30px;
            font-size: 14px;
        }

        .status {
            display: flex;
            align-items: center;
            gap: 10px;
            margin-bottom: 20px;
            padding: 15px;
            background: #f5f5f5;
            border-radius: 10px;
        }

        .status-indicator {
            width: 12px;
            height: 12px;
            border-radius: 50%;
            background: #ccc;
            transition: all 0.3s ease;
        }

        .status-indicator.listening {
            background: #ef4444;
            animation: pulse 1.5s ease-in-out infinite;
        }

        .status-indicator.loading {
            background: #f59e0b;
            animation: pulse 1.5s ease-in-out infinite;
        }

        .status-indicator.ready {
            background: #10b981;
        }

        @keyframes pulse {
            0%, 100% {
                opacity: 1;
                transform: scale(1);
            }
            50% {
                opacity: 0.5;
                transform: scale(1.1);
            }
        }

        .status-text {
            color: #666;
            font-size: 14px;
            font-weight: 500;
        }

        .loading-progress {
            width: 100%;
            height: 4px;
            background: #e5e7eb;
            border-radius: 2px;
            overflow: hidden;
            margin-top: 10px;
            display: none;
        }

        .loading-progress.show {
            display: block;
        }

        .loading-progress-bar {
            height: 100%;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            width: 0%;
            transition: width 0.3s ease;
        }

        button {
            width: 100%;
            padding: 18px 32px;
            font-size: 18px;
            font-weight: 600;
            color: white;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            border: none;
            border-radius: 12px;
            cursor: pointer;
            transition: all 0.3s ease;
            margin-bottom: 30px;
        }

        button:hover:not(:disabled) {
            transform: translateY(-2px);
            box-shadow: 0 10px 20px rgba(102, 126, 234, 0.4);
        }

        button:active:not(:disabled) {
            transform: translateY(0);
        }

        button.listening {
            background: linear-gradient(135deg, #ef4444 0%, #dc2626 100%);
        }

        button:disabled {
            background: #ccc;
            cursor: not-allowed;
            transform: none;
        }

        .results-section {
            margin-top: 20px;
        }

        .results-label {
            font-size: 12px;
            font-weight: 600;
            color: #666;
            text-transform: uppercase;
            letter-spacing: 1px;
            margin-bottom: 8px;
        }

        .results-box {
            background: #f9fafb;
            border: 2px solid #e5e7eb;
            border-radius: 10px;
            padding: 20px;
            min-height: 80px;
            margin-bottom: 20px;
            font-size: 16px;
            line-height: 1.6;
            color: #333;
        }

        .results-box.interim {
            border-color: #fbbf24;
            background: #fffbeb;
        }

        .results-box.final {
            border-color: #10b981;
            background: #f0fdf4;
        }

        .results-box.empty {
            color: #999;
            font-style: italic;
        }

        .error-message {
            background: #fef2f2;
            border: 2px solid #fecaca;
            border-radius: 10px;
            padding: 15px;
            color: #991b1b;
            margin-top: 20px;
            display: none;
        }

        .error-message.show {
            display: block;
        }

        .info-box {
            background: #eff6ff;
            border-left: 4px solid #3b82f6;
            padding: 15px;
            border-radius: 8px;
            margin-top: 20px;
            font-size: 14px;
            color: #1e40af;
        }

        .info-box.success {
            background: #f0fdf4;
            border-left-color: #10b981;
            color: #065f46;
        }

        .transcript-history {
            margin-top: 30px;
            padding-top: 20px;
            border-top: 2px solid #e5e7eb;
        }

        .history-item {
            background: #f9fafb;
            padding: 12px 16px;
            border-radius: 8px;
            margin-bottom: 10px;
            border-left: 3px solid #667eea;
        }

        .history-timestamp {
            font-size: 11px;
            color: #999;
            margin-bottom: 5px;
        }

        .features-list {
            list-style: none;
            margin-top: 10px;
        }

        .features-list li {
            padding: 5px 0;
            padding-left: 20px;
            position: relative;
        }

        .features-list li:before {
            content: "âœ“";
            position: absolute;
            left: 0;
            color: #10b981;
            font-weight: bold;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ðŸŽ¤ Speech-to-Text</h1>
        <p class="subtitle">Phase 2: On-Device WebAssembly STT (Vosk)</p>

        <div class="status">
            <div class="status-indicator" id="statusIndicator"></div>
            <div class="status-text" id="statusText">Initializing...</div>
        </div>

        <div class="loading-progress" id="loadingProgress">
            <div class="loading-progress-bar" id="loadingProgressBar"></div>
        </div>

        <button id="recordButton" disabled>Loading Model...</button>

        <div class="results-section">
            <div class="results-label">Partial Results (Real-time)</div>
            <div class="results-box interim empty" id="interimResults">
                Partial text will appear here as you speak...
            </div>

            <div class="results-label">Final Results</div>
            <div class="results-box final empty" id="finalResults">
                Final transcription will appear here...
            </div>
        </div>

        <div class="error-message" id="errorMessage"></div>

        <div class="info-box success">
            <strong>ðŸš€ Phase 2 Features:</strong>
            <ul class="features-list">
                <li>100% on-device processing (no cloud API)</li>
                <li>Complete privacy - audio never leaves your browser</li>
                <li>Zero network costs for transcription</li>
                <li>Works offline after initial model download</li>
                <li>Cross-browser compatible (Chrome, Firefox, Safari, Edge)</li>
            </ul>
        </div>

        <div class="transcript-history">
            <div class="results-label">Transcript History</div>
            <div id="historyContainer"></div>
        </div>
    </div>

    <!-- Vosk WASM Library -->
    <script src="https://cdn.jsdelivr.net/npm/vosk-browser@0.0.8/dist/vosk.js"></script>

    <script>
        // Configuration
        const MODEL_URL = 'https://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip';
        const SAMPLE_RATE = 16000;

        // State
        let voskModel = null;
        let voskRecognizer = null;
        let audioContext = null;
        let mediaStream = null;
        let audioProcessor = null;
        let isListening = false;
        let finalTranscript = '';

        // DOM Elements
        const recordButton = document.getElementById('recordButton');
        const statusIndicator = document.getElementById('statusIndicator');
        const statusText = document.getElementById('statusText');
        const interimResults = document.getElementById('interimResults');
        const finalResultsDiv = document.getElementById('finalResults');
        const errorMessage = document.getElementById('errorMessage');
        const historyContainer = document.getElementById('historyContainer');
        const loadingProgress = document.getElementById('loadingProgress');
        const loadingProgressBar = document.getElementById('loadingProgressBar');

        // Initialize Vosk
        async function initializeVosk() {
            try {
                updateStatus('loading', 'Loading WASM model...');
                loadingProgress.classList.add('show');

                // Create Vosk model
                console.log('Creating Vosk model...');
                voskModel = await Vosk.createModel(MODEL_URL, {
                    onProgress: (progress) => {
                        const percentage = Math.round(progress * 100);
                        loadingProgressBar.style.width = percentage + '%';
                        statusText.textContent = `Loading model... ${percentage}%`;
                        console.log(`Model loading: ${percentage}%`);
                    }
                });

                console.log('Model loaded successfully');

                // Create recognizer
                voskRecognizer = new voskModel.KaldiRecognizer(SAMPLE_RATE);
                voskRecognizer.setWords(true);

                // Set up result callback
                voskRecognizer.on("result", (message) => {
                    console.log('Final result:', message);
                    if (message.result && message.result.text) {
                        const text = message.result.text.trim();
                        if (text) {
                            finalTranscript += text + ' ';
                            finalResultsDiv.textContent = finalTranscript;
                            finalResultsDiv.classList.remove('empty');
                            addToHistory(text);
                        }
                    }
                });

                voskRecognizer.on("partialresult", (message) => {
                    console.log('Partial result:', message);
                    if (message.result && message.result.partial) {
                        const text = message.result.partial.trim();
                        if (text) {
                            interimResults.textContent = text;
                            interimResults.classList.remove('empty');
                        } else if (isListening) {
                            interimResults.textContent = 'Listening...';
                            interimResults.classList.remove('empty');
                        }
                    }
                });

                loadingProgress.classList.remove('show');
                updateStatus('ready', 'Ready to start');
                recordButton.disabled = false;
                recordButton.textContent = 'Start Recording';

                console.log('Vosk initialized successfully');
            } catch (error) {
                console.error('Error initializing Vosk:', error);
                showError('Failed to load speech recognition model. Please refresh the page and try again.');
                updateStatus('error', 'Failed to load model');
                loadingProgress.classList.remove('show');
            }
        }

        // Start recording
        async function startRecording() {
            try {
                // Request microphone access
                mediaStream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        channelCount: 1,
                        sampleRate: SAMPLE_RATE,
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true
                    }
                });

                // Create audio context
                audioContext = new (window.AudioContext || window.webkitAudioContext)({
                    sampleRate: SAMPLE_RATE
                });

                // Create media stream source
                const source = audioContext.createMediaStreamSource(mediaStream);

                // Create script processor for audio data
                const bufferSize = 4096;
                audioProcessor = audioContext.createScriptProcessor(bufferSize, 1, 1);

                audioProcessor.onaudioprocess = (event) => {
                    if (!isListening || !voskRecognizer) return;

                    const inputData = event.inputBuffer.getChannelData(0);

                    // Convert Float32Array to Int16Array for Vosk
                    const int16Data = new Int16Array(inputData.length);
                    for (let i = 0; i < inputData.length; i++) {
                        const s = Math.max(-1, Math.min(1, inputData[i]));
                        int16Data[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
                    }

                    // Send audio data to recognizer
                    voskRecognizer.acceptWaveform(int16Data);
                };

                // Connect the audio graph
                source.connect(audioProcessor);
                audioProcessor.connect(audioContext.destination);

                isListening = true;
                updateStatus('listening', 'Listening...');
                recordButton.textContent = 'Stop Recording';
                recordButton.classList.add('listening');

                // Clear previous results
                finalTranscript = '';
                interimResults.textContent = 'Listening...';
                interimResults.classList.remove('empty');

                // Clear error message
                errorMessage.classList.remove('show');

                console.log('Recording started');
            } catch (error) {
                console.error('Error starting recording:', error);
                if (error.name === 'NotAllowedError' || error.name === 'PermissionDeniedError') {
                    showError('Microphone permission denied. Please allow microphone access and try again.');
                } else if (error.name === 'NotFoundError') {
                    showError('No microphone found. Please connect a microphone and try again.');
                } else {
                    showError('Failed to start recording. Please try again.');
                }
                stopRecording();
            }
        }

        // Stop recording
        function stopRecording() {
            isListening = false;

            // Stop audio processing
            if (audioProcessor) {
                audioProcessor.disconnect();
                audioProcessor = null;
            }

            // Stop media stream
            if (mediaStream) {
                mediaStream.getTracks().forEach(track => track.stop());
                mediaStream = null;
            }

            // Close audio context
            if (audioContext) {
                audioContext.close();
                audioContext = null;
            }

            // Get final result from recognizer
            if (voskRecognizer) {
                try {
                    const finalResult = voskRecognizer.finalResult();
                    console.log('Final result on stop:', finalResult);
                    if (finalResult && finalResult.text) {
                        const text = finalResult.text.trim();
                        if (text) {
                            finalTranscript += text + ' ';
                            finalResultsDiv.textContent = finalTranscript;
                            finalResultsDiv.classList.remove('empty');
                            addToHistory(text);
                        }
                    }
                } catch (error) {
                    console.error('Error getting final result:', error);
                }
            }

            updateStatus('ready', 'Ready to start');
            recordButton.textContent = 'Start Recording';
            recordButton.classList.remove('listening');

            // Reset interim results
            if (!finalTranscript) {
                interimResults.textContent = 'Partial text will appear here as you speak...';
                interimResults.classList.add('empty');
            } else {
                interimResults.textContent = 'Click "Start Recording" to continue...';
                interimResults.classList.remove('empty');
            }

            console.log('Recording stopped');
        }

        // Update status UI
        function updateStatus(state, text) {
            statusText.textContent = text;
            statusIndicator.className = 'status-indicator';

            if (state === 'listening' || state === 'loading') {
                statusIndicator.classList.add(state);
            } else if (state === 'ready') {
                statusIndicator.classList.add('ready');
            }
        }

        // Show error message
        function showError(message) {
            errorMessage.textContent = message;
            errorMessage.classList.add('show');

            // Auto-hide after 10 seconds
            setTimeout(() => {
                errorMessage.classList.remove('show');
            }, 10000);
        }

        // Add transcript to history
        function addToHistory(transcript) {
            const historyItem = document.createElement('div');
            historyItem.className = 'history-item';

            const timestamp = document.createElement('div');
            timestamp.className = 'history-timestamp';
            timestamp.textContent = new Date().toLocaleTimeString();

            const text = document.createElement('div');
            text.textContent = transcript;

            historyItem.appendChild(timestamp);
            historyItem.appendChild(text);

            historyContainer.insertBefore(historyItem, historyContainer.firstChild);

            // Limit history to 10 items
            while (historyContainer.children.length > 10) {
                historyContainer.removeChild(historyContainer.lastChild);
            }
        }

        // Button click handler
        recordButton.addEventListener('click', () => {
            if (isListening) {
                stopRecording();
            } else {
                startRecording();
            }
        });

        // Keyboard shortcuts
        document.addEventListener('keydown', (event) => {
            // Space bar to toggle recording (when not typing in an input)
            if (event.code === 'Space' && event.target === document.body && !recordButton.disabled) {
                event.preventDefault();
                recordButton.click();
            }
        });

        // Initialize on page load
        window.addEventListener('load', () => {
            initializeVosk();
        });
    </script>
</body>
</html>
